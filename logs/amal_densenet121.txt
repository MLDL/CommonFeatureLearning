Namespace(batch_size=64, data_root='./data', download=False, epochs=30, gpu_id='3', lr=0.0002, model='densenet121', random_seed=1337, t1_ckpt='checkpoints/cub200_resnet18_best.pth', t2_ckpt='checkpoints/dogs_resnet34_best.pth')
CUB200, Split: train, Size: 5994
CUB200, Split: test, Size: 5794
Stanford Dogs, Split: train, Size: 12000
Stanford Dogs, Split: test, Size: 8580
Loading pretrained teachers ...
T1: resnet18, T2: resnet34
Target student: densenet121
Training ...
Epoch 0, lr = 0.000200
Epoch 0, Batch 10/281, Loss=122.324213 (ce=5.787385, cf=116.53682365417481)
Epoch 0, Batch 20/281, Loss=58.271475 (ce=5.562335, cf=52.70914001464844)
Epoch 0, Batch 30/281, Loss=50.608921 (ce=5.356266, cf=45.2526554107666)
Epoch 0, Batch 40/281, Loss=47.920564 (ce=5.081839, cf=42.83872489929199)
Epoch 0, Batch 50/281, Loss=47.129778 (ce=4.920371, cf=42.209407806396484)
Epoch 0, Batch 60/281, Loss=46.227774 (ce=4.744582, cf=41.48319206237793)
Epoch 0, Batch 70/281, Loss=46.153606 (ce=4.561082, cf=41.59252281188965)
Epoch 0, Batch 80/281, Loss=45.874224 (ce=4.363091, cf=41.5111328125)
Epoch 0, Batch 90/281, Loss=45.146038 (ce=4.287460, cf=40.85857810974121)
Epoch 0, Batch 100/281, Loss=44.858504 (ce=4.074053, cf=40.78445053100586)
Epoch 0, Batch 110/281, Loss=44.317422 (ce=3.892412, cf=40.425010681152344)
Epoch 0, Batch 120/281, Loss=44.259129 (ce=3.781166, cf=40.477962493896484)
Epoch 0, Batch 130/281, Loss=43.580912 (ce=3.690180, cf=39.89073219299316)
Epoch 0, Batch 140/281, Loss=43.714292 (ce=3.518745, cf=40.195546340942386)
Epoch 0, Batch 150/281, Loss=43.848722 (ce=3.498750, cf=40.34997215270996)
Epoch 0, Batch 160/281, Loss=42.986444 (ce=3.396337, cf=39.5901065826416)
Epoch 0, Batch 170/281, Loss=43.320469 (ce=3.300319, cf=40.020149612426756)
Epoch 0, Batch 180/281, Loss=42.947071 (ce=3.195226, cf=39.75184516906738)
Epoch 0, Batch 190/281, Loss=42.435412 (ce=3.066505, cf=39.36890640258789)
Epoch 0, Batch 200/281, Loss=42.361665 (ce=3.094755, cf=39.266909790039065)
Epoch 0, Batch 210/281, Loss=42.206256 (ce=3.005693, cf=39.20056266784668)
Epoch 0, Batch 220/281, Loss=41.709836 (ce=2.909782, cf=38.80005416870117)
Epoch 0, Batch 230/281, Loss=42.136285 (ce=2.903257, cf=39.23302803039551)
Epoch 0, Batch 240/281, Loss=41.654057 (ce=2.711048, cf=38.94300880432129)
Epoch 0, Batch 250/281, Loss=41.248257 (ce=2.703513, cf=38.54474449157715)
Epoch 0, Batch 260/281, Loss=41.556138 (ce=2.645414, cf=38.91072463989258)
Epoch 0, Batch 270/281, Loss=40.973108 (ce=2.644321, cf=38.32878723144531)
Epoch 0, Batch 280/281, Loss=40.977691 (ce=2.680724, cf=38.296967315673825)
End of Epoch 0/30, Average Loss=0.167802
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.540458
Mean Acc: 0.463283
FreqW Acc: 0.400639
Mean IoU: 0.327183

Model saved as checkpoints/amal_densenet121_best.pth
Epoch 1, lr = 0.000200
Epoch 1, Batch 10/281, Loss=40.962220 (ce=2.350052, cf=38.61216773986816)
Epoch 1, Batch 20/281, Loss=40.672248 (ce=2.389096, cf=38.283151626586914)
Epoch 1, Batch 30/281, Loss=40.578684 (ce=2.352232, cf=38.22645149230957)
Epoch 1, Batch 40/281, Loss=40.769022 (ce=2.341078, cf=38.42794342041016)
Epoch 1, Batch 50/281, Loss=40.321947 (ce=2.267083, cf=38.0548641204834)
Epoch 1, Batch 60/281, Loss=41.038415 (ce=2.263594, cf=38.77482147216797)
Epoch 1, Batch 70/281, Loss=40.260443 (ce=2.286827, cf=37.973615646362305)
Epoch 1, Batch 80/281, Loss=40.803418 (ce=2.197344, cf=38.60607376098633)
Epoch 1, Batch 90/281, Loss=40.090060 (ce=2.097176, cf=37.99288444519043)
Epoch 1, Batch 100/281, Loss=40.630296 (ce=2.128186, cf=38.50211029052734)
Epoch 1, Batch 110/281, Loss=40.249169 (ce=2.167019, cf=38.08214988708496)
Epoch 1, Batch 120/281, Loss=40.062717 (ce=2.127336, cf=37.935380935668945)
Epoch 1, Batch 130/281, Loss=39.648421 (ce=2.037096, cf=37.61132545471192)
Epoch 1, Batch 140/281, Loss=39.590078 (ce=2.066408, cf=37.52366943359375)
Epoch 1, Batch 150/281, Loss=39.431622 (ce=1.972319, cf=37.45930290222168)
Epoch 1, Batch 160/281, Loss=39.165998 (ce=2.006596, cf=37.15940208435059)
Epoch 1, Batch 170/281, Loss=39.130831 (ce=1.918801, cf=37.212030029296876)
Epoch 1, Batch 180/281, Loss=39.718340 (ce=1.998887, cf=37.71945304870606)
Epoch 1, Batch 190/281, Loss=39.009389 (ce=1.948359, cf=37.06103096008301)
Epoch 1, Batch 200/281, Loss=39.110506 (ce=1.974804, cf=37.135701751708986)
Epoch 1, Batch 210/281, Loss=39.359993 (ce=1.805716, cf=37.554276657104495)
Epoch 1, Batch 220/281, Loss=39.124387 (ce=1.900941, cf=37.223446655273435)
Epoch 1, Batch 230/281, Loss=38.839597 (ce=1.844727, cf=36.994869995117185)
Epoch 1, Batch 240/281, Loss=38.465760 (ce=1.912637, cf=36.55312309265137)
Epoch 1, Batch 250/281, Loss=38.851141 (ce=1.812662, cf=37.038478469848634)
Epoch 1, Batch 260/281, Loss=38.844187 (ce=1.852017, cf=36.99216995239258)
Epoch 1, Batch 270/281, Loss=38.578970 (ce=1.741546, cf=36.837423706054686)
Epoch 1, Batch 280/281, Loss=38.886649 (ce=1.799990, cf=37.0866584777832)
End of Epoch 1/30, Average Loss=0.141335
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.650949
Mean Acc: 0.612211
FreqW Acc: 0.512895
Mean IoU: 0.465605

Model saved as checkpoints/amal_densenet121_best.pth
Epoch 2, lr = 0.000200
Epoch 2, Batch 10/281, Loss=38.719675 (ce=1.587296, cf=37.1323787689209)
Epoch 2, Batch 20/281, Loss=38.543455 (ce=1.593967, cf=36.94948844909668)
Epoch 2, Batch 30/281, Loss=38.183731 (ce=1.556664, cf=36.627067184448244)
Epoch 2, Batch 40/281, Loss=37.972651 (ce=1.616610, cf=36.35603981018066)
Epoch 2, Batch 50/281, Loss=38.136621 (ce=1.591273, cf=36.54534721374512)
Epoch 2, Batch 60/281, Loss=37.822701 (ce=1.498908, cf=36.323794555664065)
Epoch 2, Batch 70/281, Loss=37.840705 (ce=1.644061, cf=36.1966438293457)
Epoch 2, Batch 80/281, Loss=37.801304 (ce=1.534937, cf=36.266367721557614)
Epoch 2, Batch 90/281, Loss=37.858006 (ce=1.582767, cf=36.275238800048825)
Epoch 2, Batch 100/281, Loss=38.191411 (ce=1.500451, cf=36.69096069335937)
Epoch 2, Batch 110/281, Loss=38.036480 (ce=1.581918, cf=36.45456237792969)
Epoch 2, Batch 120/281, Loss=37.605381 (ce=1.529154, cf=36.07622718811035)
Epoch 2, Batch 130/281, Loss=37.850973 (ce=1.524117, cf=36.326856231689455)
Epoch 2, Batch 140/281, Loss=37.566270 (ce=1.528592, cf=36.03767852783203)
Epoch 2, Batch 150/281, Loss=37.894585 (ce=1.486982, cf=36.40760459899902)
Epoch 2, Batch 160/281, Loss=37.516569 (ce=1.477186, cf=36.03938255310059)
Epoch 2, Batch 170/281, Loss=37.712362 (ce=1.521287, cf=36.191074752807616)
Epoch 2, Batch 180/281, Loss=37.193042 (ce=1.483690, cf=35.70935211181641)
Epoch 2, Batch 190/281, Loss=37.350269 (ce=1.507409, cf=35.84286041259766)
Epoch 2, Batch 200/281, Loss=37.259176 (ce=1.518709, cf=35.74046745300293)
Epoch 2, Batch 210/281, Loss=37.091431 (ce=1.501709, cf=35.5897216796875)
Epoch 2, Batch 220/281, Loss=36.914487 (ce=1.443067, cf=35.471419143676755)
Epoch 2, Batch 230/281, Loss=37.815798 (ce=1.529329, cf=36.28646965026856)
Epoch 2, Batch 240/281, Loss=37.329989 (ce=1.442104, cf=35.88788528442383)
Epoch 2, Batch 250/281, Loss=37.033579 (ce=1.502926, cf=35.530653381347655)
Epoch 2, Batch 260/281, Loss=36.843377 (ce=1.467252, cf=35.37612457275391)
Epoch 2, Batch 270/281, Loss=37.228393 (ce=1.505368, cf=35.72302513122558)
Epoch 2, Batch 280/281, Loss=36.561895 (ce=1.403609, cf=35.15828666687012)
End of Epoch 2/30, Average Loss=0.133944
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.716030
Mean Acc: 0.700507
FreqW Acc: 0.582085
Mean IoU: 0.554661

Model saved as checkpoints/amal_densenet121_best.pth
Epoch 3, lr = 0.000200
Epoch 3, Batch 10/281, Loss=36.551445 (ce=1.290570, cf=35.26087532043457)
Epoch 3, Batch 20/281, Loss=36.678255 (ce=1.386986, cf=35.29126892089844)
Epoch 3, Batch 30/281, Loss=36.451244 (ce=1.306082, cf=35.145162963867186)
Epoch 3, Batch 40/281, Loss=36.549582 (ce=1.231304, cf=35.318277740478514)
Epoch 3, Batch 50/281, Loss=36.938348 (ce=1.308801, cf=35.62954750061035)
Epoch 3, Batch 60/281, Loss=36.566632 (ce=1.380407, cf=35.18622512817383)
Epoch 3, Batch 70/281, Loss=36.094706 (ce=1.311205, cf=34.78350067138672)
Epoch 3, Batch 80/281, Loss=36.536022 (ce=1.295216, cf=35.24080619812012)
Epoch 3, Batch 90/281, Loss=36.383967 (ce=1.315232, cf=35.068735122680664)
Epoch 3, Batch 100/281, Loss=36.222411 (ce=1.244875, cf=34.977535247802734)
Epoch 3, Batch 110/281, Loss=36.197454 (ce=1.277215, cf=34.92023887634277)
Epoch 3, Batch 120/281, Loss=36.267368 (ce=1.289460, cf=34.977908325195315)
Epoch 3, Batch 130/281, Loss=36.477118 (ce=1.285276, cf=35.19184188842773)
Epoch 3, Batch 140/281, Loss=36.201376 (ce=1.272596, cf=34.92878036499023)
Epoch 3, Batch 150/281, Loss=36.271689 (ce=1.273379, cf=34.99831047058105)
Epoch 3, Batch 160/281, Loss=36.035218 (ce=1.320836, cf=34.71438217163086)
Epoch 3, Batch 170/281, Loss=36.385046 (ce=1.343851, cf=35.041194915771484)
Epoch 3, Batch 180/281, Loss=36.245499 (ce=1.231986, cf=35.01351356506348)
Epoch 3, Batch 190/281, Loss=35.975026 (ce=1.361355, cf=34.61366996765137)
Epoch 3, Batch 200/281, Loss=35.948919 (ce=1.252990, cf=34.6959285736084)
Epoch 3, Batch 210/281, Loss=35.775682 (ce=1.265235, cf=34.510447311401364)
Epoch 3, Batch 220/281, Loss=36.031882 (ce=1.281607, cf=34.750275421142575)
Epoch 3, Batch 230/281, Loss=35.766766 (ce=1.272682, cf=34.494084167480466)
Epoch 3, Batch 240/281, Loss=35.871310 (ce=1.319043, cf=34.55226783752441)
Epoch 3, Batch 250/281, Loss=35.177957 (ce=1.244632, cf=33.93332443237305)
Epoch 3, Batch 260/281, Loss=35.609645 (ce=1.305785, cf=34.303860092163085)
Epoch 3, Batch 270/281, Loss=35.493801 (ce=1.252479, cf=34.2413215637207)
Epoch 3, Batch 280/281, Loss=35.713762 (ce=1.270696, cf=34.44306640625)
End of Epoch 3/30, Average Loss=0.128671
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.727609
Mean Acc: 0.721824
FreqW Acc: 0.598962
Mean IoU: 0.583932

Model saved as checkpoints/amal_densenet121_best.pth
Epoch 4, lr = 0.000200
Epoch 4, Batch 10/281, Loss=35.427146 (ce=1.208560, cf=34.21858558654785)
Epoch 4, Batch 20/281, Loss=35.224668 (ce=1.161055, cf=34.06361351013184)
Epoch 4, Batch 30/281, Loss=35.470170 (ce=1.171728, cf=34.298441314697264)
Epoch 4, Batch 40/281, Loss=34.989432 (ce=1.197585, cf=33.791847229003906)
Epoch 4, Batch 50/281, Loss=35.114807 (ce=1.225544, cf=33.88926239013672)
Epoch 4, Batch 60/281, Loss=34.858667 (ce=1.133855, cf=33.72481155395508)
Epoch 4, Batch 70/281, Loss=35.383007 (ce=1.173817, cf=34.20918960571289)
Epoch 4, Batch 80/281, Loss=35.373100 (ce=1.171515, cf=34.20158500671387)
Epoch 4, Batch 90/281, Loss=35.003522 (ce=1.156448, cf=33.84707412719727)
Epoch 4, Batch 100/281, Loss=35.182485 (ce=1.163651, cf=34.0188346862793)
Epoch 4, Batch 110/281, Loss=34.568916 (ce=1.120365, cf=33.448551177978516)
Epoch 4, Batch 120/281, Loss=34.318407 (ce=1.147701, cf=33.170706558227536)
Epoch 4, Batch 130/281, Loss=34.949966 (ce=1.166508, cf=33.78345832824707)
Epoch 4, Batch 140/281, Loss=35.030288 (ce=1.151185, cf=33.87910423278809)
Epoch 4, Batch 150/281, Loss=34.697717 (ce=1.110658, cf=33.58705940246582)
Epoch 4, Batch 160/281, Loss=34.285825 (ce=1.125082, cf=33.1607421875)
Epoch 4, Batch 170/281, Loss=34.463049 (ce=1.165412, cf=33.297637176513675)
Epoch 4, Batch 180/281, Loss=34.923866 (ce=1.199705, cf=33.72416038513184)
Epoch 4, Batch 190/281, Loss=34.810018 (ce=1.138121, cf=33.67189674377441)
Epoch 4, Batch 200/281, Loss=34.567787 (ce=1.097317, cf=33.47046966552735)
Epoch 4, Batch 210/281, Loss=34.413787 (ce=1.131298, cf=33.28248901367188)
Epoch 4, Batch 220/281, Loss=34.951707 (ce=1.168894, cf=33.782812881469724)
Epoch 4, Batch 230/281, Loss=35.216549 (ce=1.232978, cf=33.983571243286136)
Epoch 4, Batch 240/281, Loss=34.371923 (ce=1.151675, cf=33.22024688720703)
Epoch 4, Batch 250/281, Loss=34.401214 (ce=1.192379, cf=33.208835220336915)
Epoch 4, Batch 260/281, Loss=34.851329 (ce=1.165959, cf=33.685370445251465)
Epoch 4, Batch 270/281, Loss=34.185978 (ce=1.189212, cf=32.99676513671875)
Epoch 4, Batch 280/281, Loss=34.276822 (ce=1.200677, cf=33.076145553588866)
End of Epoch 4/30, Average Loss=0.123945
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.739886
Mean Acc: 0.742127
FreqW Acc: 0.615497
Mean IoU: 0.607447

Model saved as checkpoints/amal_densenet121_best.pth
Epoch 5, lr = 0.000200
Epoch 5, Batch 10/281, Loss=34.275033 (ce=1.077083, cf=33.19794960021973)
Epoch 5, Batch 20/281, Loss=33.935384 (ce=1.106086, cf=32.82929801940918)
Epoch 5, Batch 30/281, Loss=33.961790 (ce=1.077682, cf=32.88410758972168)
Epoch 5, Batch 40/281, Loss=34.124152 (ce=1.091902, cf=33.03224906921387)
Epoch 5, Batch 50/281, Loss=34.576131 (ce=1.105088, cf=33.47104339599609)
Epoch 5, Batch 60/281, Loss=33.782153 (ce=1.057392, cf=32.7247615814209)
Epoch 5, Batch 70/281, Loss=34.103227 (ce=1.069543, cf=33.033684158325194)
Epoch 5, Batch 80/281, Loss=34.039912 (ce=1.022781, cf=33.01713180541992)
Epoch 5, Batch 90/281, Loss=34.012479 (ce=1.099427, cf=32.913051795959475)
Epoch 5, Batch 100/281, Loss=33.908159 (ce=1.097597, cf=32.81056251525879)
Epoch 5, Batch 110/281, Loss=33.934555 (ce=1.088444, cf=32.8461109161377)
Epoch 5, Batch 120/281, Loss=33.638131 (ce=1.091097, cf=32.54703350067139)
Epoch 5, Batch 130/281, Loss=33.960046 (ce=1.138448, cf=32.82159862518311)
Epoch 5, Batch 140/281, Loss=34.152304 (ce=1.184769, cf=32.967535400390624)
Epoch 5, Batch 150/281, Loss=33.599661 (ce=1.074711, cf=32.52495059967041)
Epoch 5, Batch 160/281, Loss=33.607520 (ce=1.060652, cf=32.54686737060547)
Epoch 5, Batch 170/281, Loss=33.275907 (ce=1.031805, cf=32.24410209655762)
Epoch 5, Batch 180/281, Loss=33.724857 (ce=1.083692, cf=32.64116382598877)
Epoch 5, Batch 190/281, Loss=33.351317 (ce=1.069989, cf=32.281326866149904)
Epoch 5, Batch 200/281, Loss=33.809889 (ce=1.101970, cf=32.707919120788574)
Epoch 5, Batch 210/281, Loss=33.351081 (ce=1.057590, cf=32.29349060058594)
Epoch 5, Batch 220/281, Loss=33.029485 (ce=1.143240, cf=31.886244583129884)
Epoch 5, Batch 230/281, Loss=33.227897 (ce=1.089911, cf=32.137986755371095)
Epoch 5, Batch 240/281, Loss=33.325963 (ce=1.122720, cf=32.203242492675784)
Epoch 5, Batch 250/281, Loss=33.028128 (ce=1.093803, cf=31.93432445526123)
Epoch 5, Batch 260/281, Loss=33.137109 (ce=1.112443, cf=32.02466659545898)
Epoch 5, Batch 270/281, Loss=33.107637 (ce=1.121514, cf=31.98612251281738)
Epoch 5, Batch 280/281, Loss=32.679221 (ce=1.131821, cf=31.547399711608886)
End of Epoch 5/30, Average Loss=0.119803
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.729074
Mean Acc: 0.728134
FreqW Acc: 0.603542
Mean IoU: 0.590526

Epoch 6, lr = 0.000200
Epoch 6, Batch 10/281, Loss=32.951820 (ce=1.044521, cf=31.90729923248291)
Epoch 6, Batch 20/281, Loss=32.999143 (ce=1.104524, cf=31.894619369506835)
Epoch 6, Batch 30/281, Loss=33.063236 (ce=1.040034, cf=32.02320232391357)
Epoch 6, Batch 40/281, Loss=32.959388 (ce=1.014755, cf=31.94463367462158)
Epoch 6, Batch 50/281, Loss=32.704053 (ce=1.037917, cf=31.666135215759276)
Epoch 6, Batch 60/281, Loss=32.546295 (ce=0.962291, cf=31.584003448486328)
Epoch 6, Batch 70/281, Loss=32.578795 (ce=0.965960, cf=31.61283473968506)
Epoch 6, Batch 80/281, Loss=32.652320 (ce=1.008105, cf=31.644215393066407)
Epoch 6, Batch 90/281, Loss=32.347128 (ce=1.070559, cf=31.276568984985353)
Epoch 6, Batch 100/281, Loss=32.460067 (ce=1.056121, cf=31.403945541381837)
Epoch 6, Batch 110/281, Loss=32.383216 (ce=1.084875, cf=31.298341369628908)
Epoch 6, Batch 120/281, Loss=32.424304 (ce=0.979750, cf=31.444553756713866)
Epoch 6, Batch 130/281, Loss=32.214894 (ce=1.001292, cf=31.213601875305176)
Epoch 6, Batch 140/281, Loss=32.172382 (ce=1.007960, cf=31.16442165374756)
Epoch 6, Batch 150/281, Loss=32.248921 (ce=1.040403, cf=31.208517837524415)
Epoch 6, Batch 160/281, Loss=32.267438 (ce=1.098759, cf=31.16867847442627)
Epoch 6, Batch 170/281, Loss=32.343504 (ce=1.046275, cf=31.297229194641112)
Epoch 6, Batch 180/281, Loss=32.332981 (ce=1.007953, cf=31.325027465820312)
Epoch 6, Batch 190/281, Loss=32.182102 (ce=1.017724, cf=31.164378356933593)
Epoch 6, Batch 200/281, Loss=32.425581 (ce=1.052168, cf=31.3734130859375)
Epoch 6, Batch 210/281, Loss=32.184775 (ce=1.060755, cf=31.12402000427246)
Epoch 6, Batch 220/281, Loss=32.229172 (ce=1.137590, cf=31.091582107543946)
Epoch 6, Batch 230/281, Loss=32.167866 (ce=1.071477, cf=31.096388816833496)
Epoch 6, Batch 240/281, Loss=31.780440 (ce=1.099900, cf=30.680540084838867)
Epoch 6, Batch 250/281, Loss=31.766896 (ce=1.074901, cf=30.691995239257814)
Epoch 6, Batch 260/281, Loss=32.035795 (ce=1.037213, cf=30.99858226776123)
Epoch 6, Batch 270/281, Loss=32.164936 (ce=1.045308, cf=31.11962776184082)
Epoch 6, Batch 280/281, Loss=31.944145 (ce=1.048467, cf=30.895677757263183)
End of Epoch 6/30, Average Loss=0.115218
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.737235
Mean Acc: 0.741376
FreqW Acc: 0.611557
Mean IoU: 0.602671

Epoch 7, lr = 0.000200
Epoch 7, Batch 10/281, Loss=32.177442 (ce=1.008776, cf=31.168665885925293)
Epoch 7, Batch 20/281, Loss=31.663565 (ce=1.019134, cf=30.644431495666502)
Epoch 7, Batch 30/281, Loss=31.583374 (ce=0.988608, cf=30.594765853881835)
Epoch 7, Batch 40/281, Loss=31.603258 (ce=1.017746, cf=30.58551197052002)
Epoch 7, Batch 50/281, Loss=31.439225 (ce=0.990818, cf=30.448406600952147)
Epoch 7, Batch 60/281, Loss=31.503768 (ce=1.024363, cf=30.479404830932616)
Epoch 7, Batch 70/281, Loss=31.557134 (ce=0.987623, cf=30.569511222839356)
Epoch 7, Batch 80/281, Loss=31.570548 (ce=1.007078, cf=30.5634708404541)
Epoch 7, Batch 90/281, Loss=31.910994 (ce=1.010046, cf=30.900947761535644)
Epoch 7, Batch 100/281, Loss=31.530739 (ce=0.972577, cf=30.558161735534668)
Epoch 7, Batch 110/281, Loss=31.689237 (ce=0.994825, cf=30.694411277770996)
Epoch 7, Batch 120/281, Loss=31.481584 (ce=0.962610, cf=30.518974113464356)
Epoch 7, Batch 130/281, Loss=31.472205 (ce=1.041975, cf=30.430229568481444)
Epoch 7, Batch 140/281, Loss=31.580929 (ce=1.066416, cf=30.514512825012208)
Epoch 7, Batch 150/281, Loss=31.415952 (ce=1.016707, cf=30.39924564361572)
Epoch 7, Batch 160/281, Loss=31.427744 (ce=0.993478, cf=30.434265899658204)
Epoch 7, Batch 170/281, Loss=31.765241 (ce=1.029461, cf=30.735780334472658)
Epoch 7, Batch 180/281, Loss=31.239675 (ce=0.981804, cf=30.2578706741333)
Epoch 7, Batch 190/281, Loss=31.313229 (ce=1.008077, cf=30.305151557922365)
Epoch 7, Batch 200/281, Loss=30.814133 (ce=1.002469, cf=29.81166362762451)
Epoch 7, Batch 210/281, Loss=31.234367 (ce=0.959728, cf=30.274638748168947)
Epoch 7, Batch 220/281, Loss=31.155854 (ce=1.015887, cf=30.139967918395996)
Epoch 7, Batch 230/281, Loss=30.798413 (ce=1.064532, cf=29.733881759643555)
Epoch 7, Batch 240/281, Loss=30.922234 (ce=1.017338, cf=29.904896926879882)
Epoch 7, Batch 250/281, Loss=30.773928 (ce=1.011679, cf=29.762249374389647)
Epoch 7, Batch 260/281, Loss=30.820641 (ce=1.008339, cf=29.812302780151366)
Epoch 7, Batch 270/281, Loss=31.235413 (ce=1.006011, cf=30.229401779174804)
Epoch 7, Batch 280/281, Loss=30.916043 (ce=1.008749, cf=29.90729389190674)
End of Epoch 7/30, Average Loss=0.111680
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.742048
Mean Acc: 0.742607
FreqW Acc: 0.620381
Mean IoU: 0.611407

Model saved as checkpoints/amal_densenet121_best.pth
Epoch 8, lr = 0.000200
Epoch 8, Batch 10/281, Loss=31.032700 (ce=0.976407, cf=30.056293487548828)
Epoch 8, Batch 20/281, Loss=31.205461 (ce=0.985357, cf=30.22010326385498)
Epoch 8, Batch 30/281, Loss=30.962467 (ce=1.018461, cf=29.944006538391115)
Epoch 8, Batch 40/281, Loss=30.653371 (ce=1.004465, cf=29.648905563354493)
Epoch 8, Batch 50/281, Loss=30.872828 (ce=0.993732, cf=29.879096031188965)
Epoch 8, Batch 60/281, Loss=31.142472 (ce=1.017301, cf=30.125170516967774)
Epoch 8, Batch 70/281, Loss=31.285811 (ce=0.972837, cf=30.312973976135254)
Epoch 8, Batch 80/281, Loss=30.565296 (ce=0.950192, cf=29.615103912353515)
Epoch 8, Batch 90/281, Loss=30.560004 (ce=0.979416, cf=29.58058738708496)
Epoch 8, Batch 100/281, Loss=30.685555 (ce=0.935616, cf=29.74993839263916)
Epoch 8, Batch 110/281, Loss=30.724187 (ce=1.027872, cf=29.696314811706543)
Epoch 8, Batch 120/281, Loss=31.017992 (ce=0.968045, cf=30.049946784973145)
Epoch 8, Batch 130/281, Loss=30.727714 (ce=0.918482, cf=29.80923194885254)
Epoch 8, Batch 140/281, Loss=31.015856 (ce=1.016039, cf=29.99981689453125)
Epoch 8, Batch 150/281, Loss=30.676096 (ce=0.992459, cf=29.683637046813963)
Epoch 8, Batch 160/281, Loss=30.965561 (ce=1.017373, cf=29.948188018798827)
Epoch 8, Batch 170/281, Loss=30.362830 (ce=1.041918, cf=29.320911979675294)
Epoch 8, Batch 180/281, Loss=30.893753 (ce=0.969699, cf=29.924053382873534)
Epoch 8, Batch 190/281, Loss=30.985535 (ce=0.972452, cf=30.01308364868164)
Epoch 8, Batch 200/281, Loss=30.695138 (ce=0.971170, cf=29.72396812438965)
Epoch 8, Batch 210/281, Loss=30.765566 (ce=0.934793, cf=29.83077220916748)
Epoch 8, Batch 220/281, Loss=30.413844 (ce=1.044040, cf=29.369804191589356)
Epoch 8, Batch 230/281, Loss=30.610792 (ce=0.907284, cf=29.70350875854492)
Epoch 8, Batch 240/281, Loss=30.639365 (ce=1.031716, cf=29.60764961242676)
Epoch 8, Batch 250/281, Loss=30.536108 (ce=1.020125, cf=29.515983200073244)
Epoch 8, Batch 260/281, Loss=30.508601 (ce=0.954581, cf=29.554020500183107)
Epoch 8, Batch 270/281, Loss=30.667078 (ce=0.986601, cf=29.68047676086426)
Epoch 8, Batch 280/281, Loss=30.538749 (ce=0.947436, cf=29.59131278991699)
End of Epoch 8/30, Average Loss=0.109530
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.757673
Mean Acc: 0.760530
FreqW Acc: 0.638323
Mean IoU: 0.634260

Model saved as checkpoints/amal_densenet121_best.pth
Epoch 9, lr = 0.000200
Epoch 9, Batch 10/281, Loss=30.057382 (ce=1.058175, cf=28.999207496643066)
Epoch 9, Batch 20/281, Loss=30.372578 (ce=0.985921, cf=29.386657333374025)
Epoch 9, Batch 30/281, Loss=30.787630 (ce=0.997027, cf=29.790603637695312)
Epoch 9, Batch 40/281, Loss=30.689068 (ce=0.965369, cf=29.723698997497557)
Epoch 9, Batch 50/281, Loss=30.435005 (ce=0.930693, cf=29.50431137084961)
Epoch 9, Batch 60/281, Loss=30.891626 (ce=0.948952, cf=29.942674255371095)
Epoch 9, Batch 70/281, Loss=30.227636 (ce=0.955949, cf=29.27168674468994)
Epoch 9, Batch 80/281, Loss=30.663311 (ce=0.925479, cf=29.73783187866211)
Epoch 9, Batch 90/281, Loss=30.112005 (ce=0.989047, cf=29.12295780181885)
Epoch 9, Batch 100/281, Loss=30.373988 (ce=1.008276, cf=29.365712356567382)
Epoch 9, Batch 110/281, Loss=30.139789 (ce=0.977742, cf=29.16204776763916)
Epoch 9, Batch 120/281, Loss=30.588623 (ce=0.918105, cf=29.670518684387208)
Epoch 9, Batch 130/281, Loss=30.491871 (ce=1.026925, cf=29.464945602416993)
Epoch 9, Batch 140/281, Loss=30.839911 (ce=0.983317, cf=29.85659465789795)
Epoch 9, Batch 150/281, Loss=30.432606 (ce=0.906159, cf=29.526447296142578)
Epoch 9, Batch 160/281, Loss=30.558237 (ce=0.915302, cf=29.642934799194336)
Epoch 9, Batch 170/281, Loss=30.342147 (ce=1.040851, cf=29.301296424865722)
Epoch 9, Batch 180/281, Loss=30.478343 (ce=1.030740, cf=29.447602844238283)
Epoch 9, Batch 190/281, Loss=30.141418 (ce=0.987894, cf=29.15352420806885)
Epoch 9, Batch 200/281, Loss=30.460562 (ce=0.889644, cf=29.570918083190918)
Epoch 9, Batch 210/281, Loss=30.522221 (ce=0.988165, cf=29.53405590057373)
Epoch 9, Batch 220/281, Loss=29.568480 (ce=0.937001, cf=28.6314790725708)
Epoch 9, Batch 230/281, Loss=30.567212 (ce=0.986392, cf=29.580820274353027)
Epoch 9, Batch 240/281, Loss=29.893993 (ce=0.986584, cf=28.907408714294434)
Epoch 9, Batch 250/281, Loss=30.290540 (ce=1.003324, cf=29.287215995788575)
Epoch 9, Batch 260/281, Loss=30.433563 (ce=1.008892, cf=29.424670791625978)
Epoch 9, Batch 270/281, Loss=30.057791 (ce=0.998770, cf=29.05902099609375)
Epoch 9, Batch 280/281, Loss=30.110346 (ce=1.010091, cf=29.100254440307616)
End of Epoch 9/30, Average Loss=0.108107
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.750837
Mean Acc: 0.752454
FreqW Acc: 0.629637
Mean IoU: 0.622057

Epoch 10, lr = 0.000200
Epoch 10, Batch 10/281, Loss=30.104341 (ce=0.980984, cf=29.123357200622557)
Epoch 10, Batch 20/281, Loss=29.969498 (ce=0.966361, cf=29.003137588500977)
Epoch 10, Batch 30/281, Loss=30.167507 (ce=0.997683, cf=29.169824600219727)
Epoch 10, Batch 40/281, Loss=30.031919 (ce=1.048179, cf=28.983740615844727)
Epoch 10, Batch 50/281, Loss=30.291569 (ce=0.963789, cf=29.3277795791626)
Epoch 10, Batch 60/281, Loss=30.398088 (ce=1.012843, cf=29.385245323181152)
Epoch 10, Batch 70/281, Loss=30.286001 (ce=0.978799, cf=29.307202339172363)
Epoch 10, Batch 80/281, Loss=30.053415 (ce=0.906659, cf=29.14675636291504)
Epoch 10, Batch 90/281, Loss=29.833974 (ce=1.004715, cf=28.82925910949707)
Epoch 10, Batch 100/281, Loss=30.280295 (ce=0.917711, cf=29.36258430480957)
Epoch 10, Batch 110/281, Loss=30.255601 (ce=0.971693, cf=29.28390884399414)
Epoch 10, Batch 120/281, Loss=29.982439 (ce=1.005524, cf=28.976915550231933)
Epoch 10, Batch 130/281, Loss=29.699863 (ce=0.966582, cf=28.733281326293945)
Epoch 10, Batch 140/281, Loss=29.790891 (ce=1.010810, cf=28.78008117675781)
Epoch 10, Batch 150/281, Loss=30.036702 (ce=0.925825, cf=29.110877227783202)
Epoch 10, Batch 160/281, Loss=29.878405 (ce=0.960728, cf=28.917676544189455)
Epoch 10, Batch 170/281, Loss=29.802177 (ce=0.970610, cf=28.831567192077635)
Epoch 10, Batch 180/281, Loss=30.030437 (ce=1.047540, cf=28.982897758483887)
Epoch 10, Batch 190/281, Loss=29.852519 (ce=0.935080, cf=28.917438507080078)
Epoch 10, Batch 200/281, Loss=29.755355 (ce=0.959120, cf=28.79623508453369)
Epoch 10, Batch 210/281, Loss=30.119669 (ce=0.926121, cf=29.193548583984374)
Epoch 10, Batch 220/281, Loss=30.142323 (ce=0.937383, cf=29.20493965148926)
Epoch 10, Batch 230/281, Loss=29.857926 (ce=0.962692, cf=28.8952335357666)
Epoch 10, Batch 240/281, Loss=29.857808 (ce=1.058535, cf=28.799273109436037)
Epoch 10, Batch 250/281, Loss=30.101410 (ce=0.998882, cf=29.10252742767334)
Epoch 10, Batch 260/281, Loss=29.936572 (ce=0.948381, cf=28.988191413879395)
Epoch 10, Batch 270/281, Loss=29.693168 (ce=0.912810, cf=28.780357933044435)
Epoch 10, Batch 280/281, Loss=29.872238 (ce=0.972214, cf=28.90002384185791)
End of Epoch 10/30, Average Loss=0.106773
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.750977
Mean Acc: 0.754655
FreqW Acc: 0.628963
Mean IoU: 0.625031

Epoch 11, lr = 0.000200
Epoch 11, Batch 10/281, Loss=29.795186 (ce=0.955072, cf=28.840114021301268)
Epoch 11, Batch 20/281, Loss=30.145263 (ce=0.950711, cf=29.194551277160645)
Epoch 11, Batch 30/281, Loss=29.704807 (ce=0.950964, cf=28.753843116760255)
Epoch 11, Batch 40/281, Loss=29.949256 (ce=1.014279, cf=28.93497657775879)
Epoch 11, Batch 50/281, Loss=29.596878 (ce=0.919270, cf=28.677607536315918)
Epoch 11, Batch 60/281, Loss=29.964410 (ce=0.939655, cf=29.024754524230957)
Epoch 11, Batch 70/281, Loss=29.706248 (ce=0.980059, cf=28.72618885040283)
Epoch 11, Batch 80/281, Loss=29.834547 (ce=0.946641, cf=28.88790645599365)
Epoch 11, Batch 90/281, Loss=29.799470 (ce=0.984157, cf=28.815312576293945)
Epoch 11, Batch 100/281, Loss=29.698511 (ce=0.910636, cf=28.787875366210937)
Epoch 11, Batch 110/281, Loss=29.539867 (ce=0.913920, cf=28.62594680786133)
Epoch 11, Batch 120/281, Loss=29.593455 (ce=0.898036, cf=28.695418930053712)
Epoch 11, Batch 130/281, Loss=29.575693 (ce=1.019485, cf=28.556207275390626)
Epoch 11, Batch 140/281, Loss=29.717203 (ce=0.975565, cf=28.741637992858887)
Epoch 11, Batch 150/281, Loss=29.840890 (ce=0.963428, cf=28.877462577819824)
Epoch 11, Batch 160/281, Loss=29.507932 (ce=0.964014, cf=28.54391689300537)
Epoch 11, Batch 170/281, Loss=29.752364 (ce=0.980857, cf=28.77150707244873)
Epoch 11, Batch 180/281, Loss=29.294067 (ce=0.933481, cf=28.36058578491211)
Epoch 11, Batch 190/281, Loss=29.649917 (ce=0.957527, cf=28.692389678955077)
Epoch 11, Batch 200/281, Loss=29.436145 (ce=0.959715, cf=28.47642993927002)
Epoch 11, Batch 210/281, Loss=29.343560 (ce=0.961205, cf=28.3823543548584)
Epoch 11, Batch 220/281, Loss=29.477374 (ce=0.961155, cf=28.516218757629396)
Epoch 11, Batch 230/281, Loss=29.816944 (ce=0.959351, cf=28.85759220123291)
Epoch 11, Batch 240/281, Loss=29.453949 (ce=0.927797, cf=28.526152038574217)
Epoch 11, Batch 250/281, Loss=29.739594 (ce=0.937051, cf=28.80254211425781)
Epoch 11, Batch 260/281, Loss=29.401255 (ce=0.948522, cf=28.452732849121094)
Epoch 11, Batch 270/281, Loss=29.074035 (ce=0.913748, cf=28.160287857055664)
Epoch 11, Batch 280/281, Loss=29.199814 (ce=0.992717, cf=28.207096672058107)
End of Epoch 11/30, Average Loss=0.105429
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.738979
Mean Acc: 0.741997
FreqW Acc: 0.618878
Mean IoU: 0.612599

Epoch 12, lr = 0.000200
Epoch 12, Batch 10/281, Loss=29.714129 (ce=0.970229, cf=28.74389934539795)
Epoch 12, Batch 20/281, Loss=28.863832 (ce=0.955033, cf=27.90879955291748)
Epoch 12, Batch 30/281, Loss=29.121992 (ce=0.863834, cf=28.258158111572264)
Epoch 12, Batch 40/281, Loss=29.002765 (ce=0.894145, cf=28.10862007141113)
Epoch 12, Batch 50/281, Loss=29.308485 (ce=0.932992, cf=28.375492286682128)
Epoch 12, Batch 60/281, Loss=29.463742 (ce=0.976601, cf=28.487141609191895)
Epoch 12, Batch 70/281, Loss=29.368828 (ce=0.934394, cf=28.43443374633789)
Epoch 12, Batch 80/281, Loss=29.135504 (ce=0.970207, cf=28.165296745300292)
Epoch 12, Batch 90/281, Loss=29.272536 (ce=0.933281, cf=28.339255332946777)
Epoch 12, Batch 100/281, Loss=29.291575 (ce=0.974491, cf=28.317084312438965)
Epoch 12, Batch 110/281, Loss=29.011315 (ce=0.953184, cf=28.05813102722168)
Epoch 12, Batch 120/281, Loss=28.631672 (ce=0.891596, cf=27.740075874328614)
Epoch 12, Batch 130/281, Loss=28.911440 (ce=0.974284, cf=27.937155532836915)
Epoch 12, Batch 140/281, Loss=29.261644 (ce=0.932244, cf=28.329400062561035)
Epoch 12, Batch 150/281, Loss=28.955433 (ce=1.007763, cf=27.94767017364502)
Epoch 12, Batch 160/281, Loss=28.987539 (ce=0.938305, cf=28.049233055114748)
Epoch 12, Batch 170/281, Loss=29.262448 (ce=0.975510, cf=28.286938285827638)
Epoch 12, Batch 180/281, Loss=28.984020 (ce=0.964672, cf=28.019347763061525)
Epoch 12, Batch 190/281, Loss=29.388984 (ce=0.952793, cf=28.436190032958983)
Epoch 12, Batch 200/281, Loss=29.443996 (ce=0.910099, cf=28.53389778137207)
Epoch 12, Batch 210/281, Loss=29.278923 (ce=0.989428, cf=28.289494705200195)
Epoch 12, Batch 220/281, Loss=28.947827 (ce=0.960976, cf=27.98685073852539)
Epoch 12, Batch 230/281, Loss=29.515305 (ce=0.930839, cf=28.584466171264648)
Epoch 12, Batch 240/281, Loss=28.958533 (ce=0.886773, cf=28.071760177612305)
Epoch 12, Batch 250/281, Loss=29.120482 (ce=0.941620, cf=28.178861618041992)
Epoch 12, Batch 260/281, Loss=29.159817 (ce=0.968259, cf=28.191557693481446)
Epoch 12, Batch 270/281, Loss=29.101768 (ce=0.945322, cf=28.15644588470459)
Epoch 12, Batch 280/281, Loss=29.273801 (ce=0.957135, cf=28.316665840148925)
End of Epoch 12/30, Average Loss=0.103789
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.750279
Mean Acc: 0.758447
FreqW Acc: 0.627599
Mean IoU: 0.624954

Epoch 13, lr = 0.000200
Epoch 13, Batch 10/281, Loss=28.918511 (ce=0.939992, cf=27.97851848602295)
Epoch 13, Batch 20/281, Loss=29.172311 (ce=0.952698, cf=28.219612884521485)
Epoch 13, Batch 30/281, Loss=28.836391 (ce=1.011631, cf=27.82475929260254)
Epoch 13, Batch 40/281, Loss=28.948681 (ce=0.937435, cf=28.011245918273925)
Epoch 13, Batch 50/281, Loss=28.603838 (ce=0.885335, cf=27.718502807617188)
Epoch 13, Batch 60/281, Loss=28.632556 (ce=0.897020, cf=27.735536193847658)
Epoch 13, Batch 70/281, Loss=29.158871 (ce=0.917913, cf=28.240958595275877)
Epoch 13, Batch 80/281, Loss=29.168552 (ce=0.926708, cf=28.24184379577637)
Epoch 13, Batch 90/281, Loss=29.305865 (ce=0.918837, cf=28.38702850341797)
Epoch 13, Batch 100/281, Loss=28.649371 (ce=0.937849, cf=27.711521911621094)
Epoch 13, Batch 110/281, Loss=28.790432 (ce=0.899437, cf=27.89099540710449)
Epoch 13, Batch 120/281, Loss=28.987127 (ce=1.041283, cf=27.9458438873291)
Epoch 13, Batch 130/281, Loss=28.864854 (ce=0.876886, cf=27.987967872619627)
Epoch 13, Batch 140/281, Loss=28.687492 (ce=0.944130, cf=27.743362426757812)
Epoch 13, Batch 150/281, Loss=28.769210 (ce=1.010131, cf=27.75907955169678)
Epoch 13, Batch 160/281, Loss=29.001524 (ce=0.951734, cf=28.049790573120116)
Epoch 13, Batch 170/281, Loss=28.692859 (ce=0.965973, cf=27.726886558532716)
Epoch 13, Batch 180/281, Loss=29.005847 (ce=0.954256, cf=28.05159111022949)
Epoch 13, Batch 190/281, Loss=28.529604 (ce=0.900477, cf=27.629127311706544)
Epoch 13, Batch 200/281, Loss=28.669346 (ce=0.898816, cf=27.770530700683594)
Epoch 13, Batch 210/281, Loss=28.758078 (ce=0.908542, cf=27.849536323547362)
Epoch 13, Batch 220/281, Loss=28.854646 (ce=0.932346, cf=27.922299575805663)
Epoch 13, Batch 230/281, Loss=28.944614 (ce=0.995338, cf=27.949275398254393)
Epoch 13, Batch 240/281, Loss=28.817262 (ce=0.972689, cf=27.84457302093506)
Epoch 13, Batch 250/281, Loss=28.974794 (ce=0.990447, cf=27.984347534179687)
Epoch 13, Batch 260/281, Loss=28.742461 (ce=0.920359, cf=27.822101974487303)
Epoch 13, Batch 270/281, Loss=28.831701 (ce=0.923819, cf=27.90788154602051)
Epoch 13, Batch 280/281, Loss=28.691689 (ce=0.946875, cf=27.744813537597658)
End of Epoch 13/30, Average Loss=0.102678
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.751744
Mean Acc: 0.756615
FreqW Acc: 0.633058
Mean IoU: 0.624373

Epoch 14, lr = 0.000020
Epoch 14, Batch 10/281, Loss=28.443205 (ce=0.962031, cf=27.481173515319824)
Epoch 14, Batch 20/281, Loss=27.986744 (ce=0.971147, cf=27.015596771240233)
Epoch 14, Batch 30/281, Loss=28.433665 (ce=0.939749, cf=27.493915557861328)
Epoch 14, Batch 40/281, Loss=28.075946 (ce=0.866520, cf=27.209425735473634)
Epoch 14, Batch 50/281, Loss=28.314547 (ce=0.948324, cf=27.36622257232666)
Epoch 14, Batch 60/281, Loss=28.094703 (ce=0.912269, cf=27.18243465423584)
Epoch 14, Batch 70/281, Loss=27.808363 (ce=0.963257, cf=26.84510498046875)
Epoch 14, Batch 80/281, Loss=27.916878 (ce=0.927939, cf=26.988938903808595)
Epoch 14, Batch 90/281, Loss=27.819847 (ce=0.944963, cf=26.874884414672852)
Epoch 14, Batch 100/281, Loss=27.951540 (ce=0.941788, cf=27.00975227355957)
Epoch 14, Batch 110/281, Loss=28.207417 (ce=0.902606, cf=27.30481071472168)
Epoch 14, Batch 120/281, Loss=27.973180 (ce=0.877107, cf=27.096072578430174)
Epoch 14, Batch 130/281, Loss=27.526497 (ce=0.882068, cf=26.644428062438966)
Epoch 14, Batch 140/281, Loss=27.960887 (ce=0.919024, cf=27.04186267852783)
Epoch 14, Batch 150/281, Loss=27.595238 (ce=0.911688, cf=26.683550071716308)
Epoch 14, Batch 160/281, Loss=27.461684 (ce=0.872783, cf=26.588900756835937)
Epoch 14, Batch 170/281, Loss=28.007588 (ce=0.994977, cf=27.01261043548584)
Epoch 14, Batch 180/281, Loss=27.973287 (ce=0.917637, cf=27.055650520324708)
Epoch 14, Batch 190/281, Loss=27.639448 (ce=0.802645, cf=26.836802673339843)
Epoch 14, Batch 200/281, Loss=28.100123 (ce=0.931594, cf=27.168528938293456)
Epoch 14, Batch 210/281, Loss=28.102680 (ce=0.906293, cf=27.196386909484865)
Epoch 14, Batch 220/281, Loss=27.606486 (ce=0.884514, cf=26.721972274780274)
Epoch 14, Batch 230/281, Loss=27.796189 (ce=0.850469, cf=26.945720291137697)
Epoch 14, Batch 240/281, Loss=27.994057 (ce=0.853701, cf=27.1403564453125)
Epoch 14, Batch 250/281, Loss=28.092885 (ce=0.934212, cf=27.158672523498534)
Epoch 14, Batch 260/281, Loss=27.771527 (ce=0.903205, cf=26.868322563171386)
Epoch 14, Batch 270/281, Loss=27.932705 (ce=0.930189, cf=27.00251636505127)
Epoch 14, Batch 280/281, Loss=27.757462 (ce=0.922669, cf=26.83479232788086)
End of Epoch 14/30, Average Loss=0.099420
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.774902
Mean Acc: 0.779709
FreqW Acc: 0.661245
Mean IoU: 0.657408

Model saved as checkpoints/amal_densenet121_best.pth
Epoch 15, lr = 0.000020
Epoch 15, Batch 10/281, Loss=27.460649 (ce=0.887695, cf=26.57295379638672)
Epoch 15, Batch 20/281, Loss=27.674136 (ce=0.905674, cf=26.768461608886717)
Epoch 15, Batch 30/281, Loss=27.957450 (ce=0.927509, cf=27.02994155883789)
Epoch 15, Batch 40/281, Loss=27.852238 (ce=0.858438, cf=26.993800354003906)
Epoch 15, Batch 50/281, Loss=28.124189 (ce=0.872644, cf=27.251544761657716)
Epoch 15, Batch 60/281, Loss=27.936853 (ce=0.825033, cf=27.111820411682128)
Epoch 15, Batch 70/281, Loss=27.774726 (ce=0.884207, cf=26.890518760681154)
Epoch 15, Batch 80/281, Loss=27.532581 (ce=0.915854, cf=26.6167272567749)
Epoch 15, Batch 90/281, Loss=28.169443 (ce=0.902100, cf=27.26734275817871)
Epoch 15, Batch 100/281, Loss=27.411121 (ce=0.890928, cf=26.520192909240723)
Epoch 15, Batch 110/281, Loss=27.550286 (ce=0.883772, cf=26.666514205932618)
Epoch 15, Batch 120/281, Loss=27.835915 (ce=0.845324, cf=26.99059009552002)
Epoch 15, Batch 130/281, Loss=27.667457 (ce=0.885455, cf=26.78200206756592)
Epoch 15, Batch 140/281, Loss=27.615155 (ce=0.910487, cf=26.704667472839354)
Epoch 15, Batch 150/281, Loss=27.859107 (ce=0.917019, cf=26.942087745666505)
Epoch 15, Batch 160/281, Loss=27.713343 (ce=0.871909, cf=26.84143352508545)
Epoch 15, Batch 170/281, Loss=27.575091 (ce=0.883542, cf=26.691549491882324)
Epoch 15, Batch 180/281, Loss=27.515788 (ce=0.897248, cf=26.618540000915527)
Epoch 15, Batch 190/281, Loss=27.867810 (ce=0.910211, cf=26.957598876953124)
Epoch 15, Batch 200/281, Loss=27.988214 (ce=0.952376, cf=27.03583679199219)
Epoch 15, Batch 210/281, Loss=27.736468 (ce=0.865726, cf=26.87074203491211)
Epoch 15, Batch 220/281, Loss=27.935945 (ce=0.894671, cf=27.041273880004884)
Epoch 15, Batch 230/281, Loss=27.447833 (ce=0.916331, cf=26.531502151489256)
Epoch 15, Batch 240/281, Loss=27.573435 (ce=0.875844, cf=26.69759006500244)
Epoch 15, Batch 250/281, Loss=27.863310 (ce=0.822607, cf=27.04070281982422)
Epoch 15, Batch 260/281, Loss=27.629685 (ce=0.898337, cf=26.731348037719727)
Epoch 15, Batch 270/281, Loss=27.565623 (ce=0.907410, cf=26.658212089538573)
Epoch 15, Batch 280/281, Loss=27.918280 (ce=0.933193, cf=26.985087203979493)
End of Epoch 15/30, Average Loss=0.098738
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.780483
Mean Acc: 0.785802
FreqW Acc: 0.669207
Mean IoU: 0.665185

Model saved as checkpoints/amal_densenet121_best.pth
Epoch 16, lr = 0.000020
Epoch 16, Batch 10/281, Loss=27.881384 (ce=0.830074, cf=27.05130977630615)
Epoch 16, Batch 20/281, Loss=27.679299 (ce=0.920234, cf=26.759065437316895)
Epoch 16, Batch 30/281, Loss=27.479823 (ce=0.876149, cf=26.60367374420166)
Epoch 16, Batch 40/281, Loss=27.335004 (ce=0.851568, cf=26.48343677520752)
Epoch 16, Batch 50/281, Loss=27.878411 (ce=0.898952, cf=26.97945919036865)
Epoch 16, Batch 60/281, Loss=27.753615 (ce=0.940301, cf=26.813314056396486)
Epoch 16, Batch 70/281, Loss=27.608897 (ce=0.862339, cf=26.746557998657227)
Epoch 16, Batch 80/281, Loss=27.346676 (ce=0.933902, cf=26.412773513793944)
Epoch 16, Batch 90/281, Loss=27.328532 (ce=0.896117, cf=26.432414627075197)
Epoch 16, Batch 100/281, Loss=27.773072 (ce=0.854243, cf=26.918829345703124)
Epoch 16, Batch 110/281, Loss=27.709935 (ce=0.907758, cf=26.80217761993408)
Epoch 16, Batch 120/281, Loss=28.000233 (ce=0.938396, cf=27.061836814880373)
Epoch 16, Batch 130/281, Loss=27.912150 (ce=0.929119, cf=26.983030700683592)
Epoch 16, Batch 140/281, Loss=27.642192 (ce=0.924172, cf=26.718020057678224)
Epoch 16, Batch 150/281, Loss=27.758880 (ce=0.890124, cf=26.868756103515626)
Epoch 16, Batch 160/281, Loss=27.468433 (ce=0.831692, cf=26.63674125671387)
Epoch 16, Batch 170/281, Loss=27.927041 (ce=0.904311, cf=27.02273006439209)
Epoch 16, Batch 180/281, Loss=27.595621 (ce=0.923965, cf=26.671655082702635)
Epoch 16, Batch 190/281, Loss=27.523161 (ce=0.897464, cf=26.62569637298584)
Epoch 16, Batch 200/281, Loss=27.868237 (ce=0.891007, cf=26.97722930908203)
Epoch 16, Batch 210/281, Loss=27.678274 (ce=0.882609, cf=26.79566478729248)
Epoch 16, Batch 220/281, Loss=27.622563 (ce=0.859224, cf=26.763339233398437)
Epoch 16, Batch 230/281, Loss=27.569980 (ce=0.866272, cf=26.703709030151366)
Epoch 16, Batch 240/281, Loss=27.554176 (ce=0.877556, cf=26.676620292663575)
Epoch 16, Batch 250/281, Loss=27.756915 (ce=0.920202, cf=26.836713218688963)
Epoch 16, Batch 260/281, Loss=27.754429 (ce=0.853967, cf=26.900462913513184)
Epoch 16, Batch 270/281, Loss=27.686255 (ce=0.853323, cf=26.83293170928955)
Epoch 16, Batch 280/281, Loss=27.458988 (ce=0.875771, cf=26.58321647644043)
End of Epoch 16/30, Average Loss=0.098439
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.778181
Mean Acc: 0.784154
FreqW Acc: 0.665758
Mean IoU: 0.662289

Epoch 17, lr = 0.000020
Epoch 17, Batch 10/281, Loss=27.715412 (ce=0.925956, cf=26.789456367492676)
Epoch 17, Batch 20/281, Loss=27.461610 (ce=0.872164, cf=26.589447021484375)
Epoch 17, Batch 30/281, Loss=27.258223 (ce=0.887352, cf=26.370870971679686)
Epoch 17, Batch 40/281, Loss=27.423438 (ce=0.944840, cf=26.47859764099121)
Epoch 17, Batch 50/281, Loss=27.532223 (ce=0.867506, cf=26.664716529846192)
Epoch 17, Batch 60/281, Loss=27.152272 (ce=0.870571, cf=26.281700897216798)
Epoch 17, Batch 70/281, Loss=27.410272 (ce=0.913708, cf=26.49656448364258)
Epoch 17, Batch 80/281, Loss=27.654147 (ce=0.827764, cf=26.82638282775879)
Epoch 17, Batch 90/281, Loss=27.753041 (ce=0.846610, cf=26.906429862976076)
Epoch 17, Batch 100/281, Loss=27.737461 (ce=0.906673, cf=26.830788993835448)
Epoch 17, Batch 110/281, Loss=27.371527 (ce=0.889349, cf=26.482177734375)
Epoch 17, Batch 120/281, Loss=27.192151 (ce=0.845132, cf=26.347019004821778)
Epoch 17, Batch 130/281, Loss=27.787660 (ce=0.828193, cf=26.95946636199951)
Epoch 17, Batch 140/281, Loss=27.670198 (ce=0.871577, cf=26.798621368408202)
Epoch 17, Batch 150/281, Loss=27.770935 (ce=0.883247, cf=26.887688064575194)
Epoch 17, Batch 160/281, Loss=27.345963 (ce=0.865928, cf=26.48003559112549)
Epoch 17, Batch 170/281, Loss=27.506270 (ce=0.909229, cf=26.597041511535643)
Epoch 17, Batch 180/281, Loss=27.807986 (ce=0.914702, cf=26.893283462524415)
Epoch 17, Batch 190/281, Loss=27.496609 (ce=0.854071, cf=26.64253787994385)
Epoch 17, Batch 200/281, Loss=27.522175 (ce=0.869947, cf=26.65222797393799)
Epoch 17, Batch 210/281, Loss=27.528208 (ce=0.895394, cf=26.63281383514404)
Epoch 17, Batch 220/281, Loss=27.632807 (ce=0.822848, cf=26.80995864868164)
Epoch 17, Batch 230/281, Loss=27.936348 (ce=0.876438, cf=27.059910583496094)
Epoch 17, Batch 240/281, Loss=27.494185 (ce=0.908998, cf=26.58518714904785)
Epoch 17, Batch 250/281, Loss=27.815313 (ce=0.951283, cf=26.864030265808104)
Epoch 17, Batch 260/281, Loss=27.255647 (ce=0.913003, cf=26.34264392852783)
Epoch 17, Batch 270/281, Loss=27.800038 (ce=0.859035, cf=26.94100284576416)
Epoch 17, Batch 280/281, Loss=27.444883 (ce=0.839072, cf=26.605810737609865)
End of Epoch 17/30, Average Loss=0.098060
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.779715
Mean Acc: 0.785683
FreqW Acc: 0.668164
Mean IoU: 0.665066

Epoch 18, lr = 0.000020
Epoch 18, Batch 10/281, Loss=27.636225 (ce=0.872090, cf=26.76413497924805)
Epoch 18, Batch 20/281, Loss=27.706851 (ce=0.970132, cf=26.736718940734864)
Epoch 18, Batch 30/281, Loss=27.563389 (ce=0.862756, cf=26.700633239746093)
Epoch 18, Batch 40/281, Loss=27.476383 (ce=0.875151, cf=26.601231956481932)
Epoch 18, Batch 50/281, Loss=27.555349 (ce=0.894245, cf=26.661104011535645)
Epoch 18, Batch 60/281, Loss=27.473902 (ce=0.836406, cf=26.637496185302734)
Epoch 18, Batch 70/281, Loss=27.564019 (ce=0.916003, cf=26.648015403747557)
Epoch 18, Batch 80/281, Loss=27.576484 (ce=0.920052, cf=26.65643177032471)
Epoch 18, Batch 90/281, Loss=27.265587 (ce=0.864115, cf=26.401471519470213)
Epoch 18, Batch 100/281, Loss=27.700307 (ce=0.886801, cf=26.813506889343262)
Epoch 18, Batch 110/281, Loss=27.770785 (ce=0.865423, cf=26.90536251068115)
Epoch 18, Batch 120/281, Loss=27.163056 (ce=0.899404, cf=26.263652038574218)
Epoch 18, Batch 130/281, Loss=27.302379 (ce=0.891077, cf=26.411301612854004)
Epoch 18, Batch 140/281, Loss=27.565566 (ce=0.861636, cf=26.7039306640625)
Epoch 18, Batch 150/281, Loss=27.469986 (ce=0.874831, cf=26.59515495300293)
Epoch 18, Batch 160/281, Loss=27.390179 (ce=0.869901, cf=26.520277976989746)
Epoch 18, Batch 170/281, Loss=27.671894 (ce=0.882551, cf=26.7893424987793)
Epoch 18, Batch 180/281, Loss=27.096226 (ce=0.862416, cf=26.233810043334962)
Epoch 18, Batch 190/281, Loss=27.290502 (ce=0.863345, cf=26.427157402038574)
Epoch 18, Batch 200/281, Loss=27.633557 (ce=0.877212, cf=26.756344985961913)
Epoch 18, Batch 210/281, Loss=27.246912 (ce=0.854159, cf=26.392753219604494)
Epoch 18, Batch 220/281, Loss=27.570560 (ce=0.862002, cf=26.70855827331543)
Epoch 18, Batch 230/281, Loss=27.356535 (ce=0.826224, cf=26.530310249328615)
Epoch 18, Batch 240/281, Loss=27.525894 (ce=0.887391, cf=26.638502883911134)
Epoch 18, Batch 250/281, Loss=27.483674 (ce=0.881547, cf=26.60212688446045)
Epoch 18, Batch 260/281, Loss=27.463999 (ce=0.823236, cf=26.640763092041016)
Epoch 18, Batch 270/281, Loss=27.205791 (ce=0.844958, cf=26.360833358764648)
Epoch 18, Batch 280/281, Loss=27.275970 (ce=0.868021, cf=26.40794906616211)
End of Epoch 18/30, Average Loss=0.097742
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.781529
Mean Acc: 0.787242
FreqW Acc: 0.670238
Mean IoU: 0.666661

Model saved as checkpoints/amal_densenet121_best.pth
Epoch 19, lr = 0.000020
Epoch 19, Batch 10/281, Loss=27.201294 (ce=0.891858, cf=26.309435081481933)
Epoch 19, Batch 20/281, Loss=27.803449 (ce=0.853656, cf=26.949792861938477)
Epoch 19, Batch 30/281, Loss=27.383896 (ce=0.931379, cf=26.452516174316408)
Epoch 19, Batch 40/281, Loss=27.607958 (ce=0.899415, cf=26.70854320526123)
Epoch 19, Batch 50/281, Loss=27.252993 (ce=0.903620, cf=26.349373435974123)
Epoch 19, Batch 60/281, Loss=27.388219 (ce=0.858769, cf=26.529450035095216)
Epoch 19, Batch 70/281, Loss=27.664078 (ce=0.878340, cf=26.785738372802733)
Epoch 19, Batch 80/281, Loss=27.457612 (ce=0.863770, cf=26.59384250640869)
Epoch 19, Batch 90/281, Loss=27.273543 (ce=0.851832, cf=26.421711349487303)
Epoch 19, Batch 100/281, Loss=27.423335 (ce=0.805974, cf=26.61736125946045)
Epoch 19, Batch 110/281, Loss=27.686242 (ce=0.901923, cf=26.78431854248047)
Epoch 19, Batch 120/281, Loss=27.356353 (ce=0.867885, cf=26.4884672164917)
Epoch 19, Batch 130/281, Loss=27.503782 (ce=0.820317, cf=26.68346424102783)
Epoch 19, Batch 140/281, Loss=27.106840 (ce=0.914409, cf=26.192430686950683)
Epoch 19, Batch 150/281, Loss=27.662142 (ce=0.897726, cf=26.76441650390625)
Epoch 19, Batch 160/281, Loss=27.567439 (ce=0.842384, cf=26.72505416870117)
Epoch 19, Batch 170/281, Loss=27.560396 (ce=0.871022, cf=26.6893741607666)
Epoch 19, Batch 180/281, Loss=27.014182 (ce=0.882479, cf=26.131702995300294)
Epoch 19, Batch 190/281, Loss=27.527303 (ce=0.911750, cf=26.615553092956542)
Epoch 19, Batch 200/281, Loss=27.536033 (ce=0.906013, cf=26.63001956939697)
Epoch 19, Batch 210/281, Loss=27.627057 (ce=0.833258, cf=26.793798828125)
Epoch 19, Batch 220/281, Loss=27.246554 (ce=0.894133, cf=26.35242042541504)
Epoch 19, Batch 230/281, Loss=27.339728 (ce=0.869249, cf=26.470479202270507)
Epoch 19, Batch 240/281, Loss=27.258133 (ce=0.821910, cf=26.436222267150878)
Epoch 19, Batch 250/281, Loss=27.226213 (ce=0.893247, cf=26.332965660095216)
Epoch 19, Batch 260/281, Loss=27.497047 (ce=0.900548, cf=26.596499633789062)
Epoch 19, Batch 270/281, Loss=26.987243 (ce=0.887674, cf=26.099568557739257)
Epoch 19, Batch 280/281, Loss=27.389919 (ce=0.865509, cf=26.52440948486328)
End of Epoch 19/30, Average Loss=0.097551
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.780552
Mean Acc: 0.787157
FreqW Acc: 0.669128
Mean IoU: 0.666608

Epoch 20, lr = 0.000020
Epoch 20, Batch 10/281, Loss=27.387659 (ce=0.878184, cf=26.509475326538087)
Epoch 20, Batch 20/281, Loss=27.145348 (ce=0.833947, cf=26.31140022277832)
Epoch 20, Batch 30/281, Loss=27.055687 (ce=0.868856, cf=26.186830520629883)
Epoch 20, Batch 40/281, Loss=27.490763 (ce=0.839349, cf=26.65141353607178)
Epoch 20, Batch 50/281, Loss=27.434008 (ce=0.913464, cf=26.52054443359375)
Epoch 20, Batch 60/281, Loss=27.382368 (ce=0.896072, cf=26.486295318603517)
Epoch 20, Batch 70/281, Loss=27.154618 (ce=0.837898, cf=26.316719627380373)
Epoch 20, Batch 80/281, Loss=27.424316 (ce=0.915568, cf=26.508748054504395)
Epoch 20, Batch 90/281, Loss=27.425374 (ce=0.901559, cf=26.523815727233888)
Epoch 20, Batch 100/281, Loss=27.358344 (ce=0.868770, cf=26.48957347869873)
Epoch 20, Batch 110/281, Loss=27.081943 (ce=0.859593, cf=26.22234973907471)
Epoch 20, Batch 120/281, Loss=27.185606 (ce=0.925548, cf=26.260057830810545)
Epoch 20, Batch 130/281, Loss=27.465662 (ce=0.884621, cf=26.581041145324708)
Epoch 20, Batch 140/281, Loss=27.347466 (ce=0.849241, cf=26.498224639892577)
Epoch 20, Batch 150/281, Loss=27.187734 (ce=0.907311, cf=26.28042278289795)
Epoch 20, Batch 160/281, Loss=27.944256 (ce=0.893357, cf=27.050898551940918)
Epoch 20, Batch 170/281, Loss=27.356347 (ce=0.855644, cf=26.500703048706054)
Epoch 20, Batch 180/281, Loss=27.424168 (ce=0.844898, cf=26.579270362854004)
Epoch 20, Batch 190/281, Loss=27.014670 (ce=0.877377, cf=26.137293434143068)
Epoch 20, Batch 200/281, Loss=27.275009 (ce=0.837523, cf=26.437486267089845)
Epoch 20, Batch 210/281, Loss=26.969104 (ce=0.874912, cf=26.09419193267822)
Epoch 20, Batch 220/281, Loss=27.331468 (ce=0.877148, cf=26.454320907592773)
Epoch 20, Batch 230/281, Loss=27.404166 (ce=0.862601, cf=26.541564559936525)
Epoch 20, Batch 240/281, Loss=27.174957 (ce=0.843753, cf=26.331203651428222)
Epoch 20, Batch 250/281, Loss=27.642046 (ce=0.823648, cf=26.81839790344238)
Epoch 20, Batch 260/281, Loss=27.055842 (ce=0.868934, cf=26.186907958984374)
Epoch 20, Batch 270/281, Loss=27.468645 (ce=0.851285, cf=26.617359733581544)
Epoch 20, Batch 280/281, Loss=27.561556 (ce=0.904749, cf=26.656807327270506)
End of Epoch 20/30, Average Loss=0.097249
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.776716
Mean Acc: 0.784265
FreqW Acc: 0.664998
Mean IoU: 0.663185

Epoch 21, lr = 0.000020
Epoch 21, Batch 10/281, Loss=27.532554 (ce=0.894144, cf=26.638409996032713)
Epoch 21, Batch 20/281, Loss=27.459678 (ce=0.915477, cf=26.544200706481934)
Epoch 21, Batch 30/281, Loss=27.165482 (ce=0.884060, cf=26.28142204284668)
Epoch 21, Batch 40/281, Loss=27.351124 (ce=0.839715, cf=26.511408805847168)
Epoch 21, Batch 50/281, Loss=27.425707 (ce=0.860409, cf=26.56529769897461)
Epoch 21, Batch 60/281, Loss=27.215129 (ce=0.813629, cf=26.40150089263916)
Epoch 21, Batch 70/281, Loss=27.098955 (ce=0.856583, cf=26.24237232208252)
Epoch 21, Batch 80/281, Loss=27.402372 (ce=0.814687, cf=26.587684631347656)
Epoch 21, Batch 90/281, Loss=27.405737 (ce=0.898135, cf=26.507603263854982)
Epoch 21, Batch 100/281, Loss=27.137752 (ce=0.886907, cf=26.25084533691406)
Epoch 21, Batch 110/281, Loss=26.908510 (ce=0.886566, cf=26.021943855285645)
Epoch 21, Batch 120/281, Loss=27.543345 (ce=0.882421, cf=26.66092414855957)
Epoch 21, Batch 130/281, Loss=27.365882 (ce=0.901086, cf=26.464795303344726)
Epoch 21, Batch 140/281, Loss=27.256391 (ce=0.909310, cf=26.34708023071289)
Epoch 21, Batch 150/281, Loss=26.906684 (ce=0.868560, cf=26.038124084472656)
Epoch 21, Batch 160/281, Loss=26.871147 (ce=0.871621, cf=25.999525833129884)
Epoch 21, Batch 170/281, Loss=27.556643 (ce=0.909895, cf=26.646747589111328)
Epoch 21, Batch 180/281, Loss=26.922663 (ce=0.857315, cf=26.06534824371338)
Epoch 21, Batch 190/281, Loss=27.240247 (ce=0.845780, cf=26.394467163085938)
Epoch 21, Batch 200/281, Loss=27.176120 (ce=0.859096, cf=26.317024612426756)
Epoch 21, Batch 210/281, Loss=27.332009 (ce=0.826555, cf=26.505453872680665)
Epoch 21, Batch 220/281, Loss=27.151472 (ce=0.819633, cf=26.33183822631836)
Epoch 21, Batch 230/281, Loss=27.270284 (ce=0.902688, cf=26.367595672607422)
Epoch 21, Batch 240/281, Loss=27.393718 (ce=0.782652, cf=26.611066627502442)
Epoch 21, Batch 250/281, Loss=26.930956 (ce=0.850743, cf=26.080213165283205)
Epoch 21, Batch 260/281, Loss=27.153500 (ce=0.909179, cf=26.244320487976076)
Epoch 21, Batch 270/281, Loss=27.452735 (ce=0.891306, cf=26.56142921447754)
Epoch 21, Batch 280/281, Loss=27.191593 (ce=0.851069, cf=26.340523338317873)
End of Epoch 21/30, Average Loss=0.096950
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.779925
Mean Acc: 0.787028
FreqW Acc: 0.668237
Mean IoU: 0.666443

Epoch 22, lr = 0.000020
Epoch 22, Batch 10/281, Loss=27.385221 (ce=0.883542, cf=26.5016788482666)
Epoch 22, Batch 20/281, Loss=27.421350 (ce=0.891148, cf=26.53020133972168)
Epoch 22, Batch 30/281, Loss=27.016602 (ce=0.874169, cf=26.142432975769044)
Epoch 22, Batch 40/281, Loss=27.248984 (ce=0.909791, cf=26.33919277191162)
Epoch 22, Batch 50/281, Loss=27.039162 (ce=0.803885, cf=26.235277557373045)
Epoch 22, Batch 60/281, Loss=27.080932 (ce=0.846985, cf=26.23394718170166)
Epoch 22, Batch 70/281, Loss=27.504130 (ce=0.953571, cf=26.550559043884277)
Epoch 22, Batch 80/281, Loss=27.294424 (ce=0.843064, cf=26.45136070251465)
Epoch 22, Batch 90/281, Loss=27.364315 (ce=0.936532, cf=26.427783012390137)
Epoch 22, Batch 100/281, Loss=27.192214 (ce=0.862204, cf=26.330009841918944)
Epoch 22, Batch 110/281, Loss=27.134720 (ce=0.881825, cf=26.252894783020018)
Epoch 22, Batch 120/281, Loss=27.222991 (ce=0.855753, cf=26.367238235473632)
Epoch 22, Batch 130/281, Loss=27.348457 (ce=0.906829, cf=26.441627502441406)
Epoch 22, Batch 140/281, Loss=27.078359 (ce=0.796179, cf=26.282179832458496)
Epoch 22, Batch 150/281, Loss=26.884299 (ce=0.904929, cf=25.97936954498291)
Epoch 22, Batch 160/281, Loss=26.829094 (ce=0.819672, cf=26.00942268371582)
Epoch 22, Batch 170/281, Loss=27.125428 (ce=0.822631, cf=26.30279655456543)
Epoch 22, Batch 180/281, Loss=27.366534 (ce=0.848470, cf=26.518064308166505)
Epoch 22, Batch 190/281, Loss=27.017561 (ce=0.905335, cf=26.11222610473633)
Epoch 22, Batch 200/281, Loss=27.153342 (ce=0.857912, cf=26.2954309463501)
Epoch 22, Batch 210/281, Loss=27.474823 (ce=0.798728, cf=26.676095008850098)
Epoch 22, Batch 220/281, Loss=26.859924 (ce=0.860045, cf=25.99987907409668)
Epoch 22, Batch 230/281, Loss=27.129654 (ce=0.795180, cf=26.33447399139404)
Epoch 22, Batch 240/281, Loss=27.264405 (ce=0.881500, cf=26.38290500640869)
Epoch 22, Batch 250/281, Loss=27.184750 (ce=0.880843, cf=26.30390682220459)
Epoch 22, Batch 260/281, Loss=27.159105 (ce=0.914139, cf=26.24496555328369)
Epoch 22, Batch 270/281, Loss=27.099959 (ce=0.832794, cf=26.267164611816405)
Epoch 22, Batch 280/281, Loss=26.878628 (ce=0.838312, cf=26.040316009521483)
End of Epoch 22/30, Average Loss=0.096680
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.780064
Mean Acc: 0.785367
FreqW Acc: 0.670016
Mean IoU: 0.665855

Epoch 23, lr = 0.000020
Epoch 23, Batch 10/281, Loss=27.364401 (ce=0.856310, cf=26.508091354370116)
Epoch 23, Batch 20/281, Loss=27.106053 (ce=0.874312, cf=26.231740951538086)
Epoch 23, Batch 30/281, Loss=26.945685 (ce=0.857767, cf=26.087917518615722)
Epoch 23, Batch 40/281, Loss=26.925093 (ce=0.915926, cf=26.009167671203613)
Epoch 23, Batch 50/281, Loss=26.911900 (ce=0.837467, cf=26.074432945251466)
Epoch 23, Batch 60/281, Loss=27.026593 (ce=0.847547, cf=26.179046630859375)
Epoch 23, Batch 70/281, Loss=27.057833 (ce=0.916021, cf=26.141812133789063)
Epoch 23, Batch 80/281, Loss=27.009025 (ce=0.798705, cf=26.21031951904297)
Epoch 23, Batch 90/281, Loss=27.040822 (ce=0.839605, cf=26.20121650695801)
Epoch 23, Batch 100/281, Loss=27.044228 (ce=0.861120, cf=26.183107948303224)
Epoch 23, Batch 110/281, Loss=27.337655 (ce=0.823322, cf=26.514333152770995)
Epoch 23, Batch 120/281, Loss=27.403039 (ce=0.855754, cf=26.547285270690917)
Epoch 23, Batch 130/281, Loss=26.995163 (ce=0.907125, cf=26.08803787231445)
Epoch 23, Batch 140/281, Loss=27.030685 (ce=0.869262, cf=26.161423110961913)
Epoch 23, Batch 150/281, Loss=27.181221 (ce=0.831849, cf=26.349371910095215)
Epoch 23, Batch 160/281, Loss=27.012487 (ce=0.878840, cf=26.133647155761718)
Epoch 23, Batch 170/281, Loss=27.154118 (ce=0.876881, cf=26.277236557006837)
Epoch 23, Batch 180/281, Loss=27.336050 (ce=0.867969, cf=26.46808032989502)
Epoch 23, Batch 190/281, Loss=27.255386 (ce=0.909323, cf=26.346063804626464)
Epoch 23, Batch 200/281, Loss=27.390960 (ce=0.824754, cf=26.566206550598146)
Epoch 23, Batch 210/281, Loss=27.321202 (ce=0.923734, cf=26.39746856689453)
Epoch 23, Batch 220/281, Loss=26.894526 (ce=0.806673, cf=26.087852478027344)
Epoch 23, Batch 230/281, Loss=27.039943 (ce=0.925913, cf=26.114030265808104)
Epoch 23, Batch 240/281, Loss=26.946446 (ce=0.841552, cf=26.10489444732666)
Epoch 23, Batch 250/281, Loss=27.177569 (ce=0.899957, cf=26.2776123046875)
Epoch 23, Batch 260/281, Loss=27.102221 (ce=0.802040, cf=26.30018081665039)
Epoch 23, Batch 270/281, Loss=27.014602 (ce=0.842297, cf=26.172304534912108)
Epoch 23, Batch 280/281, Loss=27.326063 (ce=0.827319, cf=26.49874382019043)
End of Epoch 23/30, Average Loss=0.096503
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.780134
Mean Acc: 0.786547
FreqW Acc: 0.667448
Mean IoU: 0.663497

Epoch 24, lr = 0.000020
Epoch 24, Batch 10/281, Loss=27.007817 (ce=0.900337, cf=26.107480239868163)
Epoch 24, Batch 20/281, Loss=27.093823 (ce=0.874611, cf=26.21921157836914)
Epoch 24, Batch 30/281, Loss=27.230385 (ce=0.797883, cf=26.432501983642577)
Epoch 24, Batch 40/281, Loss=27.046188 (ce=0.828121, cf=26.218066787719728)
Epoch 24, Batch 50/281, Loss=27.014753 (ce=0.848304, cf=26.16644916534424)
Epoch 24, Batch 60/281, Loss=27.216044 (ce=0.876132, cf=26.339912033081056)
Epoch 24, Batch 70/281, Loss=26.929155 (ce=0.906000, cf=26.02315444946289)
Epoch 24, Batch 80/281, Loss=26.951789 (ce=0.898630, cf=26.053159141540526)
Epoch 24, Batch 90/281, Loss=27.070499 (ce=0.890784, cf=26.17971477508545)
Epoch 24, Batch 100/281, Loss=27.179257 (ce=0.859243, cf=26.320013427734374)
Epoch 24, Batch 110/281, Loss=27.134486 (ce=0.827576, cf=26.306909370422364)
Epoch 24, Batch 120/281, Loss=27.021930 (ce=0.904350, cf=26.117580223083497)
Epoch 24, Batch 130/281, Loss=26.821731 (ce=0.829097, cf=25.992634582519532)
Epoch 24, Batch 140/281, Loss=26.811947 (ce=0.858531, cf=25.95341567993164)
Epoch 24, Batch 150/281, Loss=27.046139 (ce=0.930311, cf=26.11582851409912)
Epoch 24, Batch 160/281, Loss=27.041832 (ce=0.805843, cf=26.235988998413085)
Epoch 24, Batch 170/281, Loss=26.796714 (ce=0.884245, cf=25.912469482421876)
Epoch 24, Batch 180/281, Loss=26.999308 (ce=0.819700, cf=26.179608154296876)
Epoch 24, Batch 190/281, Loss=27.369629 (ce=0.908645, cf=26.46098384857178)
Epoch 24, Batch 200/281, Loss=27.338317 (ce=0.817652, cf=26.520665550231932)
Epoch 24, Batch 210/281, Loss=26.742850 (ce=0.869019, cf=25.87383117675781)
Epoch 24, Batch 220/281, Loss=27.025622 (ce=0.861297, cf=26.16432476043701)
Epoch 24, Batch 230/281, Loss=27.146474 (ce=0.814983, cf=26.331490898132323)
Epoch 24, Batch 240/281, Loss=27.163486 (ce=0.847852, cf=26.315633964538574)
Epoch 24, Batch 250/281, Loss=27.143603 (ce=0.897587, cf=26.24601650238037)
Epoch 24, Batch 260/281, Loss=27.109346 (ce=0.847019, cf=26.262326812744142)
Epoch 24, Batch 270/281, Loss=26.725825 (ce=0.850193, cf=25.875632286071777)
Epoch 24, Batch 280/281, Loss=27.123981 (ce=0.903099, cf=26.22088165283203)
End of Epoch 24/30, Average Loss=0.096250
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.779297
Mean Acc: 0.786043
FreqW Acc: 0.667048
Mean IoU: 0.663098

Epoch 25, lr = 0.000020
Epoch 25, Batch 10/281, Loss=26.665008 (ce=0.873773, cf=25.79123477935791)
Epoch 25, Batch 20/281, Loss=26.812063 (ce=0.794868, cf=26.017195892333984)
Epoch 25, Batch 30/281, Loss=26.592103 (ce=0.831674, cf=25.760429191589356)
Epoch 25, Batch 40/281, Loss=26.647266 (ce=0.850006, cf=25.797259521484374)
Epoch 25, Batch 50/281, Loss=27.248032 (ce=0.854177, cf=26.393855094909668)
Epoch 25, Batch 60/281, Loss=26.923121 (ce=0.913739, cf=26.009382057189942)
Epoch 25, Batch 70/281, Loss=26.785804 (ce=0.830049, cf=25.95575523376465)
Epoch 25, Batch 80/281, Loss=26.894131 (ce=0.887608, cf=26.00652332305908)
Epoch 25, Batch 90/281, Loss=27.059237 (ce=0.828024, cf=26.231212615966797)
Epoch 25, Batch 100/281, Loss=27.186093 (ce=0.833445, cf=26.35264835357666)
Epoch 25, Batch 110/281, Loss=26.907722 (ce=0.845287, cf=26.062434959411622)
Epoch 25, Batch 120/281, Loss=27.128422 (ce=0.851935, cf=26.276487350463867)
Epoch 25, Batch 130/281, Loss=27.188343 (ce=0.849056, cf=26.33928737640381)
Epoch 25, Batch 140/281, Loss=26.916276 (ce=0.913804, cf=26.00247116088867)
Epoch 25, Batch 150/281, Loss=26.879408 (ce=0.832883, cf=26.04652519226074)
Epoch 25, Batch 160/281, Loss=26.944160 (ce=0.843724, cf=26.100435256958008)
Epoch 25, Batch 170/281, Loss=27.188235 (ce=0.887149, cf=26.301085662841796)
Epoch 25, Batch 180/281, Loss=26.923330 (ce=0.869507, cf=26.053822898864745)
Epoch 25, Batch 190/281, Loss=27.053000 (ce=0.904602, cf=26.148398399353027)
Epoch 25, Batch 200/281, Loss=27.058167 (ce=0.843505, cf=26.21466121673584)
Epoch 25, Batch 210/281, Loss=27.092413 (ce=0.842726, cf=26.24968719482422)
Epoch 25, Batch 220/281, Loss=26.873399 (ce=0.922199, cf=25.951200866699217)
Epoch 25, Batch 230/281, Loss=26.809212 (ce=0.781753, cf=26.027458953857423)
Epoch 25, Batch 240/281, Loss=26.769799 (ce=0.848984, cf=25.920814514160156)
Epoch 25, Batch 250/281, Loss=27.318011 (ce=0.924767, cf=26.393244171142577)
Epoch 25, Batch 260/281, Loss=26.564838 (ce=0.827215, cf=25.73762321472168)
Epoch 25, Batch 270/281, Loss=27.019973 (ce=0.944110, cf=26.075863075256347)
Epoch 25, Batch 280/281, Loss=26.959145 (ce=0.861004, cf=26.098140716552734)
End of Epoch 25/30, Average Loss=0.095898
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.775391
Mean Acc: 0.782089
FreqW Acc: 0.662193
Mean IoU: 0.657730

Epoch 26, lr = 0.000020
Epoch 26, Batch 10/281, Loss=26.882657 (ce=0.860206, cf=26.022451210021973)
Epoch 26, Batch 20/281, Loss=26.814406 (ce=0.794299, cf=26.020108032226563)
Epoch 26, Batch 30/281, Loss=27.173341 (ce=0.850415, cf=26.322926330566407)
Epoch 26, Batch 40/281, Loss=27.018153 (ce=0.897104, cf=26.12104949951172)
Epoch 26, Batch 50/281, Loss=27.013019 (ce=0.917439, cf=26.095580291748046)
Epoch 26, Batch 60/281, Loss=26.759534 (ce=0.864831, cf=25.894702911376953)
Epoch 26, Batch 70/281, Loss=26.910944 (ce=0.829256, cf=26.08168773651123)
Epoch 26, Batch 80/281, Loss=27.163169 (ce=0.889831, cf=26.273336982727052)
Epoch 26, Batch 90/281, Loss=27.099125 (ce=0.842711, cf=26.256413650512695)
Epoch 26, Batch 100/281, Loss=27.048972 (ce=0.858617, cf=26.19035587310791)
Epoch 26, Batch 110/281, Loss=26.996560 (ce=0.890142, cf=26.10641860961914)
Epoch 26, Batch 120/281, Loss=26.989677 (ce=0.886911, cf=26.10276641845703)
Epoch 26, Batch 130/281, Loss=26.872602 (ce=0.879375, cf=25.993227386474608)
Epoch 26, Batch 140/281, Loss=26.618783 (ce=0.909562, cf=25.70922107696533)
Epoch 26, Batch 150/281, Loss=27.132174 (ce=0.877888, cf=26.254286003112792)
Epoch 26, Batch 160/281, Loss=26.883064 (ce=0.819824, cf=26.06323947906494)
Epoch 26, Batch 170/281, Loss=26.762288 (ce=0.811159, cf=25.95112895965576)
Epoch 26, Batch 180/281, Loss=26.847170 (ce=0.849000, cf=25.998170471191408)
Epoch 26, Batch 190/281, Loss=26.936023 (ce=0.844189, cf=26.091834259033202)
Epoch 26, Batch 200/281, Loss=26.889884 (ce=0.848465, cf=26.041419219970702)
Epoch 26, Batch 210/281, Loss=26.820513 (ce=0.878182, cf=25.942331314086914)
Epoch 26, Batch 220/281, Loss=26.861807 (ce=0.831533, cf=26.030273818969725)
Epoch 26, Batch 230/281, Loss=26.686048 (ce=0.860312, cf=25.82573528289795)
Epoch 26, Batch 240/281, Loss=27.028744 (ce=0.869318, cf=26.159426498413087)
Epoch 26, Batch 250/281, Loss=26.762522 (ce=0.797455, cf=25.965067291259764)
Epoch 26, Batch 260/281, Loss=26.767189 (ce=0.860721, cf=25.906467819213866)
Epoch 26, Batch 270/281, Loss=26.731259 (ce=0.834545, cf=25.896713638305663)
Epoch 26, Batch 280/281, Loss=26.974195 (ce=0.864003, cf=26.110191917419435)
End of Epoch 26/30, Average Loss=0.095761
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.779785
Mean Acc: 0.786217
FreqW Acc: 0.668042
Mean IoU: 0.664118

Epoch 27, lr = 0.000020
Epoch 27, Batch 10/281, Loss=26.752284 (ce=0.888904, cf=25.86338005065918)
Epoch 27, Batch 20/281, Loss=26.950641 (ce=0.839807, cf=26.110833740234376)
Epoch 27, Batch 30/281, Loss=26.676853 (ce=0.859486, cf=25.817366790771484)
Epoch 27, Batch 40/281, Loss=26.646983 (ce=0.827357, cf=25.819625854492188)
Epoch 27, Batch 50/281, Loss=26.639263 (ce=0.810654, cf=25.828609275817872)
Epoch 27, Batch 60/281, Loss=27.012956 (ce=0.852015, cf=26.160941314697265)
Epoch 27, Batch 70/281, Loss=26.732427 (ce=0.833118, cf=25.899308586120604)
Epoch 27, Batch 80/281, Loss=27.073177 (ce=0.824676, cf=26.248501014709472)
Epoch 27, Batch 90/281, Loss=26.792764 (ce=0.854918, cf=25.937845039367676)
Epoch 27, Batch 100/281, Loss=26.577933 (ce=0.879274, cf=25.698659133911132)
Epoch 27, Batch 110/281, Loss=26.664268 (ce=0.858533, cf=25.805735778808593)
Epoch 27, Batch 120/281, Loss=27.004489 (ce=0.823442, cf=26.181046104431154)
Epoch 27, Batch 130/281, Loss=26.932039 (ce=0.853305, cf=26.078733444213867)
Epoch 27, Batch 140/281, Loss=26.665771 (ce=0.791099, cf=25.874673080444335)
Epoch 27, Batch 150/281, Loss=26.611794 (ce=0.840225, cf=25.77156867980957)
Epoch 27, Batch 160/281, Loss=27.089944 (ce=0.934908, cf=26.15503635406494)
Epoch 27, Batch 170/281, Loss=26.885488 (ce=0.890645, cf=25.99484348297119)
Epoch 27, Batch 180/281, Loss=26.673397 (ce=0.857902, cf=25.815495109558107)
Epoch 27, Batch 190/281, Loss=26.676017 (ce=0.878775, cf=25.797241973876954)
Epoch 27, Batch 200/281, Loss=26.724097 (ce=0.862916, cf=25.861180686950682)
Epoch 27, Batch 210/281, Loss=26.781455 (ce=0.888592, cf=25.89286289215088)
Epoch 27, Batch 220/281, Loss=27.029943 (ce=0.888706, cf=26.141237449645995)
Epoch 27, Batch 230/281, Loss=27.097173 (ce=0.835139, cf=26.262034225463868)
Epoch 27, Batch 240/281, Loss=26.750390 (ce=0.896573, cf=25.85381736755371)
Epoch 27, Batch 250/281, Loss=26.998705 (ce=0.861467, cf=26.137237548828125)
Epoch 27, Batch 260/281, Loss=26.725123 (ce=0.886483, cf=25.83863945007324)
Epoch 27, Batch 270/281, Loss=26.864448 (ce=0.854214, cf=26.01023464202881)
Epoch 27, Batch 280/281, Loss=26.680699 (ce=0.869675, cf=25.81102409362793)
End of Epoch 27/30, Average Loss=0.095413
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.779576
Mean Acc: 0.786359
FreqW Acc: 0.667649
Mean IoU: 0.665342

Epoch 28, lr = 0.000020
Epoch 28, Batch 10/281, Loss=26.807624 (ce=0.811729, cf=25.995895385742188)
Epoch 28, Batch 20/281, Loss=26.639592 (ce=0.814850, cf=25.824742126464844)
Epoch 28, Batch 30/281, Loss=26.714068 (ce=0.873169, cf=25.8408992767334)
Epoch 28, Batch 40/281, Loss=26.601613 (ce=0.792186, cf=25.80942726135254)
Epoch 28, Batch 50/281, Loss=26.917384 (ce=0.839049, cf=26.07833480834961)
Epoch 28, Batch 60/281, Loss=26.930565 (ce=0.894701, cf=26.035865020751952)
Epoch 28, Batch 70/281, Loss=26.993401 (ce=0.820348, cf=26.173052978515624)
Epoch 28, Batch 80/281, Loss=27.023656 (ce=0.834100, cf=26.189556312561034)
Epoch 28, Batch 90/281, Loss=26.470291 (ce=0.823844, cf=25.64644660949707)
Epoch 28, Batch 100/281, Loss=26.841435 (ce=0.876402, cf=25.96503257751465)
Epoch 28, Batch 110/281, Loss=26.905727 (ce=0.861043, cf=26.0446834564209)
Epoch 28, Batch 120/281, Loss=26.796539 (ce=0.897288, cf=25.89925193786621)
Epoch 28, Batch 130/281, Loss=26.468734 (ce=0.869870, cf=25.598863220214845)
Epoch 28, Batch 140/281, Loss=26.686094 (ce=0.857272, cf=25.828821754455568)
Epoch 28, Batch 150/281, Loss=26.959696 (ce=0.849225, cf=26.110470581054688)
Epoch 28, Batch 160/281, Loss=26.395294 (ce=0.933094, cf=25.46219959259033)
Epoch 28, Batch 170/281, Loss=26.826671 (ce=0.844361, cf=25.98231086730957)
Epoch 28, Batch 180/281, Loss=26.617019 (ce=0.893676, cf=25.723343276977538)
Epoch 28, Batch 190/281, Loss=26.754528 (ce=0.874002, cf=25.880525970458983)
Epoch 28, Batch 200/281, Loss=26.855049 (ce=0.856988, cf=25.998061752319337)
Epoch 28, Batch 210/281, Loss=26.905008 (ce=0.845145, cf=26.059863090515137)
Epoch 28, Batch 220/281, Loss=27.009524 (ce=0.857237, cf=26.15228691101074)
Epoch 28, Batch 230/281, Loss=26.588087 (ce=0.889842, cf=25.698245239257812)
Epoch 28, Batch 240/281, Loss=26.859731 (ce=0.903017, cf=25.956713485717774)
Epoch 28, Batch 250/281, Loss=26.718315 (ce=0.841960, cf=25.87635498046875)
Epoch 28, Batch 260/281, Loss=26.794325 (ce=0.898369, cf=25.895955657958986)
Epoch 28, Batch 270/281, Loss=26.774498 (ce=0.887939, cf=25.886559104919435)
Epoch 28, Batch 280/281, Loss=26.720821 (ce=0.821281, cf=25.89953956604004)
End of Epoch 28/30, Average Loss=0.095270
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.779227
Mean Acc: 0.785295
FreqW Acc: 0.667263
Mean IoU: 0.663804

Epoch 29, lr = 0.000002
Epoch 29, Batch 10/281, Loss=26.674042 (ce=0.874402, cf=25.79963970184326)
Epoch 29, Batch 20/281, Loss=26.503619 (ce=0.841670, cf=25.661949157714844)
Epoch 29, Batch 30/281, Loss=26.592135 (ce=0.775618, cf=25.81651725769043)
Epoch 29, Batch 40/281, Loss=26.818883 (ce=0.883026, cf=25.93585662841797)
Epoch 29, Batch 50/281, Loss=26.329085 (ce=0.867277, cf=25.461807441711425)
Epoch 29, Batch 60/281, Loss=26.730775 (ce=0.879184, cf=25.851591300964355)
Epoch 29, Batch 70/281, Loss=26.726472 (ce=0.857481, cf=25.868991470336915)
Epoch 29, Batch 80/281, Loss=26.171240 (ce=0.909192, cf=25.262048149108885)
Epoch 29, Batch 90/281, Loss=26.797617 (ce=0.883260, cf=25.914356422424316)
Epoch 29, Batch 100/281, Loss=26.740949 (ce=0.908107, cf=25.832841682434083)
Epoch 29, Batch 110/281, Loss=26.588380 (ce=0.838081, cf=25.750299644470214)
Epoch 29, Batch 120/281, Loss=26.591406 (ce=0.879010, cf=25.712396812438964)
Epoch 29, Batch 130/281, Loss=26.431335 (ce=0.889093, cf=25.542241668701173)
Epoch 29, Batch 140/281, Loss=26.910736 (ce=0.817386, cf=26.093350219726563)
Epoch 29, Batch 150/281, Loss=26.712321 (ce=0.904107, cf=25.808213806152345)
Epoch 29, Batch 160/281, Loss=26.454138 (ce=0.803432, cf=25.650705909729005)
Epoch 29, Batch 170/281, Loss=26.897350 (ce=0.844282, cf=26.05306758880615)
Epoch 29, Batch 180/281, Loss=26.645986 (ce=0.815876, cf=25.830109786987304)
Epoch 29, Batch 190/281, Loss=26.482044 (ce=0.824227, cf=25.657817077636718)
Epoch 29, Batch 200/281, Loss=26.648519 (ce=0.831733, cf=25.816785430908205)
Epoch 29, Batch 210/281, Loss=26.476639 (ce=0.823982, cf=25.652657508850098)
Epoch 29, Batch 220/281, Loss=26.611377 (ce=0.837608, cf=25.773769187927247)
Epoch 29, Batch 230/281, Loss=26.658278 (ce=0.900256, cf=25.758021926879884)
Epoch 29, Batch 240/281, Loss=26.777859 (ce=0.896350, cf=25.881509590148926)
Epoch 29, Batch 250/281, Loss=26.648925 (ce=0.850098, cf=25.79882678985596)
Epoch 29, Batch 260/281, Loss=26.505729 (ce=0.839492, cf=25.666236877441406)
Epoch 29, Batch 270/281, Loss=26.282883 (ce=0.875551, cf=25.407332038879396)
Epoch 29, Batch 280/281, Loss=26.058124 (ce=0.854481, cf=25.20364284515381)
End of Epoch 29/30, Average Loss=0.094625
Model saved as checkpoints/amal_densenet121_latest.pth
validate on val set...

Overall Acc: 0.779227
Mean Acc: 0.785742
FreqW Acc: 0.667159
Mean IoU: 0.664024

